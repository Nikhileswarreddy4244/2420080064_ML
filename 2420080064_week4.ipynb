{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Experiment 4: Machine Learning - Linear & Logistic Regression\n",
                "\n",
                "This notebook demonstrates:\n",
                "- **Part A**: Linear Regression on synthetic data\n",
                "- **Part B**: Logistic Regression on the Breast Cancer dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.datasets import make_regression, load_breast_cancer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Set style for better visualizations\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette(\"husl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART A: LINEAR REGRESSION\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Creating Synthetic Regression Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"1. Creating synthetic regression dataset...\")\n",
                "X, y = make_regression(n_samples=300, n_features=1, noise=15, random_state=42)\n",
                "\n",
                "# Split data into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
                "print(f\"Testing set size: {X_test.shape[0]} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Training Linear Regression Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Training Linear Regression model...\")\n",
                "linear_model = LinearRegression()\n",
                "linear_model.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_train_pred = linear_model.predict(X_train)\n",
                "y_test_pred = linear_model.predict(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Performance Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate metrics\n",
                "mse_train = mean_squared_error(y_train, y_train_pred)\n",
                "mse_test = mean_squared_error(y_test, y_test_pred)\n",
                "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
                "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
                "r2_train = r2_score(y_train, y_train_pred)\n",
                "r2_test = r2_score(y_test, y_test_pred)\n",
                "\n",
                "print(\"Model Performance Metrics:\")\n",
                "print(\"-\" * 40)\n",
                "print(f\"Training MSE: {mse_train:.4f}\")\n",
                "print(f\"Testing MSE: {mse_test:.4f}\")\n",
                "print(f\"Training MAE: {mae_train:.4f}\")\n",
                "print(f\"Testing MAE: {mae_test:.4f}\")\n",
                "print(f\"Training R² Score: {r2_train:.4f}\")\n",
                "print(f\"Testing R² Score: {r2_test:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Coefficients"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Model Coefficients:\")\n",
                "print(\"-\" * 40)\n",
                "print(f\"Intercept (β₀): {linear_model.intercept_:.4f}\")\n",
                "print(f\"Coefficient (β₁): {linear_model.coef_[0]:.4f}\")\n",
                "\n",
                "print(\"\\nInterpretation:\")\n",
                "print(\"-\" * 40)\n",
                "print(\"• Intercept (β₀): Expected value of y when all features are 0\")\n",
                "print(f\"• Coefficient (β₁): For each unit increase in X, y increases by {linear_model.coef_[0]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualization: Regression Line vs Actual Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Training set plot\n",
                "axes[0].scatter(X_train, y_train, alpha=0.7, label='Actual data', color='blue')\n",
                "axes[0].plot(X_train, y_train_pred, color='red', linewidth=2, label='Regression line')\n",
                "axes[0].set_xlabel('Feature X')\n",
                "axes[0].set_ylabel('Target y')\n",
                "axes[0].set_title('Linear Regression - Training Set')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Testing set plot\n",
                "axes[1].scatter(X_test, y_test, alpha=0.7, label='Actual data', color='green')\n",
                "axes[1].plot(X_test, y_test_pred, color='red', linewidth=2, label='Regression line')\n",
                "axes[1].set_xlabel('Feature X')\n",
                "axes[1].set_ylabel('Target y')\n",
                "axes[1].set_title('Linear Regression - Testing Set')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART B: LOGISTIC REGRESSION\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Loading the Breast Cancer Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading Cancer dataset...\")\n",
                "data = load_breast_cancer()\n",
                "X = data.data\n",
                "y = data.target\n",
                "\n",
                "print(f\"Dataset shape: {X.shape}\")\n",
                "print(f\"Number of features: {X.shape[1]}\")\n",
                "print(f\"Classes: {data.target_names}\")\n",
                "print(f\"Features: {data.feature_names[:5]}...\")  # Show first 5 features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Splitting and Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.3, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
                "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
                "print(f\"Class distribution in training set: {np.bincount(y_train)}\")\n",
                "print(f\"Class distribution in testing set: {np.bincount(y_test)}\")\n",
                "\n",
                "# Standardize features for better convergence\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Logistic Regression Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Training Logistic Regression model...\")\n",
                "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
                "logistic_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_train_pred = logistic_model.predict(X_train_scaled)\n",
                "y_test_pred = logistic_model.predict(X_test_scaled)\n",
                "y_test_prob = logistic_model.predict_proba(X_test_scaled)[:, 1]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Performance Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate metrics\n",
                "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
                "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
                "precision = precision_score(y_test, y_test_pred)\n",
                "recall = recall_score(y_test, y_test_pred)\n",
                "f1 = f1_score(y_test, y_test_pred)\n",
                "\n",
                "print(\"Model Performance Metrics:\")\n",
                "print(\"-\" * 40)\n",
                "print(f\"Training Accuracy: {accuracy_train:.4f}\")\n",
                "print(f\"Testing Accuracy: {accuracy_test:.4f}\")\n",
                "print(f\"Precision: {precision:.4f}\")\n",
                "print(f\"Recall: {recall:.4f}\")\n",
                "print(f\"F1-Score: {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Confusion Matrix and Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_test, y_test_pred)\n",
                "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)\n",
                "disp.plot(ax=axes[0], cmap='Blues')\n",
                "axes[0].set_title('Confusion Matrix')\n",
                "\n",
                "# Feature importance (top 10 coefficients)\n",
                "feature_importance = pd.DataFrame({\n",
                "    'Feature': data.feature_names,\n",
                "    'Coefficient': logistic_model.coef_[0]\n",
                "})\n",
                "feature_importance['Abs_Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
                "feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
                "\n",
                "# Plot top 10 features\n",
                "top_features = feature_importance.head(10)\n",
                "colors = ['red' if x < 0 else 'green' for x in top_features['Coefficient']]\n",
                "axes[1].barh(range(len(top_features)), top_features['Coefficient'], color=colors)\n",
                "axes[1].set_yticks(range(len(top_features)))\n",
                "axes[1].set_yticklabels(top_features['Feature'])\n",
                "axes[1].set_xlabel('Coefficient Value')\n",
                "axes[1].set_title('Top 10 Most Important Features')\n",
                "axes[1].invert_yaxis()  # Highest coefficient at top\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Coefficient Interpretation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Top 10 Model Coefficients (Feature Importance):\")\n",
                "print(\"-\" * 40)\n",
                "for idx, row in top_features.iterrows():\n",
                "    direction = \"increases\" if row['Coefficient'] > 0 else \"decreases\"\n",
                "    print(f\"{row['Feature']:25} Coefficient: {row['Coefficient']:8.4f} ({direction} probability of malignant)\")\n",
                "\n",
                "print(\"\\nInterpretation:\")\n",
                "print(\"-\" * 40)\n",
                "print(\"• Positive coefficients increase probability of malignant class\")\n",
                "print(\"• Negative coefficients decrease probability of malignant class\")\n",
                "print(\"• Larger absolute values indicate stronger feature influence\")\n",
                "print(f\"\\nModel intercept: {logistic_model.intercept_[0]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Decision Boundary Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Decision Boundary Visualization (using two most important features)...\")\n",
                "\n",
                "top_two_features = feature_importance.head(2)['Feature'].values\n",
                "\n",
                "# Find indices of top two features\n",
                "idx1 = np.where(data.feature_names == top_two_features[0])[0][0]\n",
                "idx2 = np.where(data.feature_names == top_two_features[1])[0][0]\n",
                "\n",
                "# Train new model with only two features for visualization\n",
                "X_two_features = X[:, [idx1, idx2]]\n",
                "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(\n",
                "    X_two_features, y, test_size=0.3, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "# Standardize\n",
                "scaler_2d = StandardScaler()\n",
                "X_train_2d_scaled = scaler_2d.fit_transform(X_train_2d)\n",
                "X_test_2d_scaled = scaler_2d.transform(X_test_2d)\n",
                "\n",
                "# Train model\n",
                "model_2d = LogisticRegression(max_iter=1000, random_state=42)\n",
                "model_2d.fit(X_train_2d_scaled, y_train_2d)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create mesh for decision boundary\n",
                "x_min, x_max = X_train_2d_scaled[:, 0].min() - 1, X_train_2d_scaled[:, 0].max() + 1\n",
                "y_min, y_max = X_train_2d_scaled[:, 1].min() - 1, X_train_2d_scaled[:, 1].max() + 1\n",
                "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
                "                     np.arange(y_min, y_max, 0.02))\n",
                "\n",
                "# Predict for each point in mesh\n",
                "Z = model_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
                "Z = Z.reshape(xx.shape)\n",
                "\n",
                "# Plot decision boundary\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
                "scatter = plt.scatter(X_train_2d_scaled[:, 0], X_train_2d_scaled[:, 1],\n",
                "                     c=y_train_2d, cmap='RdYlBu', edgecolors='k', alpha=0.7)\n",
                "plt.xlabel(f'{top_two_features[0]} (scaled)')\n",
                "plt.ylabel(f'{top_two_features[1]} (scaled)')\n",
                "plt.title(f'Decision Boundary: {top_two_features[0]} vs {top_two_features[1]}')\n",
                "plt.colorbar(scatter, label='Class (0=Benign, 1=Malignant)')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Program Completed Successfully\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"PROGRAM COMPLETED SUCCESSFULLY\")\n",
                "print(\"=\" * 60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}